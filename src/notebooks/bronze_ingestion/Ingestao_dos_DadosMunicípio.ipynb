{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "814ebcf7-c4f3-4174-bb58-5c4cced59a1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parâmetros iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e68ecd47-945d-4e03-a69a-f0aa109e6490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install openpyxl\n",
    "import os, io, csv, hashlib, datetime, re, requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from pyspark.sql import functions as F, types as T\n",
    "\n",
    "CATALOG        = \"sinesp\"\n",
    "SCHEMA_BRONZE  = \"bronze\"\n",
    "LANDING_MUNIC  = \"/Volumes/sinesp/source/landing/sinesp/municipios\"\n",
    "\n",
    "UFS = [\"AC\",\"AL\",\"AP\",\"AM\",\"BA\",\"CE\",\"DF\",\"ES\",\"GO\",\"MA\",\"MT\",\"MS\",\n",
    "       \"MG\",\"PA\",\"PB\",\"PR\",\"PE\",\"PI\",\"RJ\",\"RN\",\"RS\",\"RO\",\"RR\",\"SC\",\"SP\",\"SE\",\"TO\"]\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA_BRONZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c301c63b-ffc4-4e4c-b61a-b6d9a95026b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Localizar XLSX mais recente na landing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d510d2d6-ee7e-4d87-9906-31fcb8010f36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_files = (spark.read.format(\"binaryFile\")\n",
    "            .option(\"recursiveFileLookup\", \"true\")\n",
    "            .load(LANDING_MUNIC)\n",
    "            .filter(F.lower(F.col(\"path\")).endswith(\".xlsx\"))\n",
    "            .select(\"path\",\"modificationTime\"))\n",
    "\n",
    "latest = df_files.orderBy(F.col(\"modificationTime\").desc()).limit(1).collect()\n",
    "if not latest:\n",
    "    raise FileNotFoundError(f\"Nenhum XLSX encontrado em {LANDING_MUNIC}\")\n",
    "\n",
    "latest_path = latest[0][\"path\"]\n",
    "print(f\"Usando arquivo de municípios: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2acf1eb4-429a-4cdf-826a-5668839d0c07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Abrir XLSX via Spark -> Bytes -> pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68a1ce1c-c042-4f2a-b08e-25c93d485933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_bytes = (spark.read.format(\"binaryFile\")\n",
    "              .load(latest_path)\n",
    "              .select(\"content\")\n",
    "              .head()[0])\n",
    "\n",
    "xls = pd.ExcelFile(BytesIO(file_bytes))\n",
    "sheet_ufs = [s for s in xls.sheet_names if s in UFS]\n",
    "print(\"Abas (UFs) detectadas:\", sheet_ufs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e25c51fb-4df1-4c66-9139-de79ebcbdec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Helpers de normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d3a7fcb-a86c-4d82-ae5f-6b13183071b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Ingestão + transformação Bronze (loop por UF) ---\n",
    "accum = None\n",
    "rows_written_by_uf = []\n",
    "\n",
    "for uf in sheet_ufs:\n",
    "    print(f\"Processando aba {uf}...\")\n",
    "\n",
    "    # 1) Ler aba\n",
    "    pdf = pd.read_excel(xls, sheet_name=uf, dtype=str)\n",
    "    if pdf.empty:\n",
    "        print(f\"  [skip] aba {uf} vazia (sem linhas)\")\n",
    "        continue\n",
    "\n",
    "    # 2) Normalizar colunas\n",
    "    pdf = normalize_columns_pdf(pdf)\n",
    "\n",
    "    # 3) Selecionar colunas principais (mantém 'mes_ano' como rescue)\n",
    "    expected = [\"cod_ibge\",\"municipio\",\"uf\",\"regiao\",\"mes_ano\",\"vitimas\"]\n",
    "    existing = [c for c in expected if c in pdf.columns]\n",
    "    pdf = pdf[existing].copy()\n",
    "\n",
    "    # 4) UF da aba\n",
    "    pdf[\"uf\"] = uf\n",
    "\n",
    "    # 5) Casts mínimos (aceitando nulos)\n",
    "    if \"cod_ibge\" in pdf.columns:\n",
    "        pdf[\"cod_ibge\"] = pd.to_numeric(pdf[\"cod_ibge\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    if \"vitimas\" in pdf.columns:\n",
    "        pdf[\"vitimas\"] = pd.to_numeric(pdf[\"vitimas\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # 6) Derivar year, month, year_month (parser robusto)\n",
    "    if \"mes_ano\" in pdf.columns:\n",
    "        ym = pdf[\"mes_ano\"].apply(parse_mes_ano)\n",
    "        pdf[\"year\"]  = ym.apply(lambda t: t[0] if pd.notna(t[0]) else pd.NA).astype(\"Int64\")\n",
    "        pdf[\"month\"] = ym.apply(lambda t: t[1] if pd.notna(t[1]) else pd.NA).astype(\"Int64\")\n",
    "        ys = pdf[\"year\"].astype(\"string\")\n",
    "        ms = pdf[\"month\"].astype(\"string\").str.zfill(2)\n",
    "        pdf[\"year_month\"] = pd.to_datetime(ys + \"-\" + ms + \"-01\", errors=\"coerce\")\n",
    "    else:\n",
    "        pdf[\"year\"]       = pd.Series(dtype=\"Int64\")\n",
    "        pdf[\"month\"]      = pd.Series(dtype=\"Int64\")\n",
    "        pdf[\"year_month\"] = pd.to_datetime(pd.Series(dtype=\"string\"), errors=\"coerce\")\n",
    "\n",
    "    # 7) Metadados\n",
    "    pdf[\"_ingestion_ts\"] = ingestion_ts\n",
    "    pdf[\"_source_path\"]  = latest_path\n",
    "\n",
    "    # 8) Checks leves (não derruba por year_month nulo na Bronze)\n",
    "    before = len(pdf)\n",
    "    pdf = pdf[pdf[\"uf\"] == uf]  # consistência de UF\n",
    "    if \"vitimas\" in pdf.columns:\n",
    "        pdf = pdf[pdf[\"vitimas\"].isna() | (pdf[\"vitimas\"] >= 0)]  # sem negativos\n",
    "    after = len(pdf)\n",
    "    if after < before:\n",
    "        print(f\"  [warn] {before - after} linha(s) removida(s) por checks leves\")\n",
    "\n",
    "    # Se ficou vazio, pula\n",
    "    if pdf.empty:\n",
    "        print(f\"  [skip] aba {uf} ficou vazia após checks leves\")\n",
    "        continue\n",
    "\n",
    "    # 9) Para Spark + ajuste de tipos finais\n",
    "    df = (spark.createDataFrame(pdf.astype(object))\n",
    "          .withColumn(\"year\",       F.col(\"year\").cast(T.IntegerType()))\n",
    "          .withColumn(\"month\",      F.col(\"month\").cast(T.IntegerType()))\n",
    "          .withColumn(\"year_month\", F.to_date(\"year_month\"))\n",
    "          .withColumn(\"cod_ibge\",   F.col(\"cod_ibge\").cast(T.LongType()))\n",
    "          .withColumn(\"vitimas\",    F.col(\"vitimas\").cast(T.IntegerType()))\n",
    "          .withColumn(\"_ingestion_ts\", F.col(\"_ingestion_ts\").cast(T.TimestampType()))\n",
    "         )\n",
    "\n",
    "    # 10) Escrever tabela por UF (1ª vez overwrite; depois use 'append')\n",
    "    tbl = f\"{CATALOG}.{SCHEMA_BRONZE}.DadosMunicipio{uf}\"\n",
    "    (df.write\n",
    "       .format(\"delta\")\n",
    "       .mode(\"overwrite\")\n",
    "       .option(\"overwriteSchema\",\"true\")\n",
    "       .saveAsTable(tbl))\n",
    "    n = df.count()\n",
    "    rows_written_by_uf.append((uf, n))\n",
    "    print(f\"  [ok] gravado: {tbl} | linhas: {n}\")\n",
    "\n",
    "    # 11) Acumular para unificada\n",
    "    accum = df if accum is None else accum.unionByName(df, allowMissingColumns=True)\n",
    "\n",
    "# --- Tabela unificada (fora do loop) ---\n",
    "if accum is not None:\n",
    "    unified_tbl = f\"{CATALOG}.{SCHEMA_BRONZE}.municipios_raw_row\"\n",
    "    (accum.write\n",
    "       .format(\"delta\")\n",
    "       .mode(\"overwrite\")              # nas próximas execuções, trocar para 'append'\n",
    "       .option(\"overwriteSchema\",\"true\")\n",
    "       .partitionBy(\"uf\",\"year\",\"month\")\n",
    "       .saveAsTable(unified_tbl))\n",
    "    print(f\"[ok] gravado também: {unified_tbl} (particionado por uf/year/month)\")\n",
    "else:\n",
    "    print(\"Nenhuma aba processada.\")\n",
    "\n",
    "print(\"Resumo por UF (linhas escritas):\", rows_written_by_uf)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingestao_dos_DadosMunicípio",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
